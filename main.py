import os
import yaml
import time
import requests
import datetime
import sqlite3
from bs4 import BeautifulSoup
from openai import OpenAI

# === 1. é…ç½®åŠ è½½ ===
def load_config():
    if not os.path.exists("config.yaml"):
        print("âŒ é”™è¯¯: æ‰¾ä¸åˆ° config.yaml")
        exit(1)
    with open("config.yaml", "r", encoding="utf-8") as f:
        config = yaml.safe_load(f)
    
    # ç¯å¢ƒå˜é‡è¦†ç›– (æ”¯æŒ GitHub Actions)
    env_enable_llm = os.environ.get("ENABLE_LLM")
    if env_enable_llm is not None:
        config['settings']['enable_llm'] = (env_enable_llm.lower() == 'true')
    return config

# === 2. æ•°æ®åº“ç®¡ç† (SQLite) ===
DB_PATH = "data/history.db"

def init_db():
    """åˆå§‹åŒ–æ•°æ®åº“è¡¨"""
    os.makedirs(os.path.dirname(DB_PATH), exist_ok=True)
    with sqlite3.connect(DB_PATH) as conn:
        conn.execute("""
            CREATE TABLE IF NOT EXISTS project_history (
                name TEXT PRIMARY KEY,
                summary TEXT,
                updated_at TEXT
            )
        """)
        conn.execute("CREATE INDEX IF NOT EXISTS idx_name ON project_history (name)")

def get_cached_summary(name):
    """ä»æ•°æ®åº“æŸ¥è¯¢æ‘˜è¦"""
    if not os.path.exists(DB_PATH):
        return None
    
    with sqlite3.connect(DB_PATH) as conn:
        cursor = conn.execute("SELECT summary FROM project_history WHERE name = ?", (name,))
        row = cursor.fetchone()
        return row[0] if row else None

def save_cached_summary(name, summary):
    """ä¿å­˜æ‘˜è¦åˆ°æ•°æ®åº“"""
    today = datetime.datetime.now().strftime("%Y-%m-%d")
    with sqlite3.connect(DB_PATH) as conn:
        # ä½¿ç”¨ REPLACE INTOï¼Œå¦‚æœå­˜åœ¨åˆ™æ›´æ–°ï¼Œä¸å­˜åœ¨åˆ™æ’å…¥
        conn.execute("""
            REPLACE INTO project_history (name, summary, updated_at) 
            VALUES (?, ?, ?)
        """, (name, summary, today))

# === 3. çˆ¬è™«é€»è¾‘ (BeautifulSoup) ===
def scrape_github_trending(url, limit=10):
    """
    æŠ“å– GitHub Trending é¡µé¢å¹¶è§£æ
    """
    print(f"ğŸ“¡ æ­£åœ¨æŠ“å–: {url} ...")
    headers = {
        "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
    }
    
    try:
        resp = requests.get(url, headers=headers, timeout=20)
        if resp.status_code != 200:
            print(f"âŒ è¯·æ±‚å¤±è´¥: {resp.status_code}")
            return []
            
        soup = BeautifulSoup(resp.text, 'html.parser')
        repos = []
        
        # éå†æ–‡ç« åˆ—è¡¨ (GitHub ç›®å‰ä½¿ç”¨ article.Box-row)
        items = soup.select('article.Box-row')
        
        for item in items[:limit]: # è¿™é‡Œç›´æ¥åšæˆªæ–­
            try:
                # 1. è·å–é¡¹ç›®åå’Œé“¾æ¥
                h2_a = item.select_one('h2 a')
                if not h2_a: continue
                
                href = h2_a['href'].strip() # /owner/repo
                full_name = href.strip('/') # owner/repo
                repo_url = f"https://github.com{href}"
                
                # 2. è·å–æè¿°
                p_desc = item.select_one('p.col-9')
                description = p_desc.text.strip() if p_desc else "æ— æè¿°"
                
                # 3. è·å– Stars (ç²—ç•¥è·å–å½“æ—¥æ–°å¢æˆ–æ€»æ˜Ÿæ•°)
                stars_elem = item.select_one('a[href$="/stargazers"]')
                stars = stars_elem.text.strip() if stars_elem else "N/A"
                
                repos.append({
                    "repo_name": full_name,
                    "url": repo_url,
                    "description": description,
                    "stars": stars
                })
            except Exception as e:
                print(f"âš ï¸ è§£æå•ä¸ªé¡¹ç›®å‡ºé”™: {e}")
                continue
                
        return repos

    except Exception as e:
        print(f"âŒ çˆ¬è™«å¼‚å¸¸: {e}")
        return []

# === 4. AI æ‘˜è¦ç”Ÿæˆ ===
def generate_ai_summary(client, repo, model_name):
    if not client: return ""
    
    name = repo['repo_name']
    desc = repo['description']
    
    prompt = (
        f"é¡¹ç›®: {name}\n"
        f"æè¿°: {desc}\n"
        "è¯·ç”¨ä¸­æ–‡ä¸€å¥è¯æ¦‚æ‹¬è¿™ä¸ªé¡¹ç›®çš„æ ¸å¿ƒåŠŸèƒ½ï¼Œä¸è¦åºŸè¯ã€‚"
    )

    try:
        response = client.chat.completions.create(
            model=model_name,
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæŠ€æœ¯ä¸“å®¶ã€‚"},
                {"role": "user", "content": prompt}
            ],
            max_tokens=100,
            temperature=0.3
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        print(f"âš ï¸ AI æ¥å£é”™è¯¯: {e}")
        return ""

# === 5. Markdown æ„å»º (é›†æˆ SQLite) ===
def build_section(title, repos, settings, llm_client):
    section = f"## {title}\n\n"
    section += "| æ’å | é¡¹ç›® | Stars | ç®€ä»‹ (AI/Raw) |\n"
    section += "| :--- | :--- | :--- | :--- |\n"

    for idx, repo in enumerate(repos, 1):
        name = repo['repo_name']
        url = repo['url']
        stars = repo['stars']
        raw_desc = repo['description'].replace('|', '\|').replace('\n', ' ')
        
        final_desc = raw_desc
        
        # AI é€»è¾‘
        if settings['enable_llm']:
            # 1. å°è¯•ä» SQLite æŸ¥ç¼“å­˜
            cached_summary = get_cached_summary(name)
            
            if cached_summary:
                final_desc = f"ğŸ¤– {cached_summary}"
            
            # 2. å¦‚æœæ²¡ç¼“å­˜ï¼Œä¸”æœ‰ Clientï¼Œåˆ™ç”Ÿæˆå¹¶ä¿å­˜
            elif llm_client:
                ai_sum = generate_ai_summary(llm_client, repo, settings.get('ai_model', 'gpt-3.5-turbo'))
                if ai_sum:
                    final_desc = f"ğŸ¤– {ai_sum}"
                    # å†™å…¥ SQLite
                    save_cached_summary(name, ai_sum)
        
        # æˆªæ–­é•¿æ–‡æœ¬
        if len(final_desc) > 150:
            final_desc = final_desc[:147] + "..."

        section += f"| {idx} | [{name}]({url}) | {stars} | {final_desc} |\n"
    
    return section

# === 6. å½’æ¡£ç´¢å¼•åˆ—è¡¨ ===
def get_archive_list(archive_dir):
    if not os.path.exists(archive_dir): return []
    files = [f for f in os.listdir(archive_dir) if f.endswith('.md')]
    files.sort(reverse=True) # æ—¥æœŸå€’åº
    
    lines = []
    for f in files:
        date = f.replace('.md', '')
        lines.append(f"| {date} | [æŸ¥çœ‹æ—¥æŠ¥](./{archive_dir}/{f}) |")
    return lines

# === ä¸»ç¨‹åº ===
def main():
    config = load_config()
    settings = config['settings']
    
    # åˆå§‹åŒ–æ•°æ®åº“
    init_db()
    
    # åˆå§‹åŒ– AI å®¢æˆ·ç«¯
    llm_client = None
    if settings['enable_llm']:
        api_key = os.environ.get("OPENAI_API_KEY")
        base_url = os.environ.get("OPENAI_BASE_URL")
        if api_key:
            llm_client = OpenAI(api_key=api_key, base_url=base_url)

    # å‡†å¤‡å†…å®¹
    today = datetime.datetime.now().strftime("%Y-%m-%d")
    update_time = datetime.datetime.now().strftime("%Y-%m-%d %H:%M UTC")
    
    report_content = settings['readme_header'].replace("{{ update_time }}", update_time) + "\n\n"

    # éå†ä»»åŠ¡
    for item in config['collections']:
        limit = settings.get('top_list_limit', 10)
        repos = scrape_github_trending(item['url'], limit=limit)
        
        if repos:
            section_md = build_section(item['title'], repos, settings, llm_client)
            report_content += section_md + "\n"
        
        time.sleep(2) # é˜²å° IP å»¶è¿Ÿ

    # ä¿å­˜ä»Šæ—¥å½’æ¡£
    archive_dir = settings['archive_dir']
    os.makedirs(archive_dir, exist_ok=True)
    with open(os.path.join(archive_dir, f"{today}.md"), "w", encoding="utf-8") as f:
        f.write(report_content)
    print(f"âœ… ä»Šæ—¥å½’æ¡£å·²ç”Ÿæˆ: {today}.md")

    # æ›´æ–° README (å¤´éƒ¨ + å½’æ¡£åˆ—è¡¨)
    archive_list = get_archive_list(archive_dir)
    history_section = "\n## ğŸ—‚ å†å²å½’æ¡£ (Archives)\n\n| æ—¥æœŸ | é“¾æ¥ |\n| :--- | :--- |\n"
    # ä»…æ˜¾ç¤ºæœ€è¿‘ 14 æ¡
    history_section += "\n".join(archive_list[:14]) 
    
    with open(settings['readme_file'], "w", encoding="utf-8") as f:
        f.write(report_content + history_section)
    print("âœ… README å·²æ›´æ–°")

if __name__ == "__main__":
    main()
