import os
import json
import yaml
import time
import requests
import datetime
from bs4 import BeautifulSoup
from openai import OpenAI

# === 1. é…ç½®åŠ è½½ ===
def load_config():
    if not os.path.exists("config.yaml"):
        print("âŒ é”™è¯¯: æ‰¾ä¸åˆ° config.yaml")
        exit(1)
    with open("config.yaml", "r", encoding="utf-8") as f:
        config = yaml.safe_load(f)
    
    # ç¯å¢ƒå˜é‡è¦†ç›– (æ”¯æŒ GitHub Actions)
    env_enable_llm = os.environ.get("ENABLE_LLM")
    if env_enable_llm is not None:
        config['settings']['enable_llm'] = (env_enable_llm.lower() == 'true')
    return config

# === 2. å†å²ç¼“å­˜ (å»é‡æ ¸å¿ƒ) ===
def load_history(filepath):
    if not os.path.exists(filepath):
        return {}
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            return json.load(f)
    except:
        return {}

def save_history(filepath, history):
    os.makedirs(os.path.dirname(filepath), exist_ok=True)
    with open(filepath, 'w', encoding='utf-8') as f:
        json.dump(history, f, ensure_ascii=False, indent=2)

# === 3. çˆ¬è™«é€»è¾‘ (BeautifulSoup) ===
def scrape_github_trending(url, limit=10):
    """
    æŠ“å– GitHub Trending é¡µé¢å¹¶è§£æ
    """
    print(f"ğŸ“¡ æ­£åœ¨æŠ“å–: {url} ...")
    headers = {
        "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
    }
    
    try:
        resp = requests.get(url, headers=headers, timeout=20)
        if resp.status_code != 200:
            print(f"âŒ è¯·æ±‚å¤±è´¥: {resp.status_code}")
            return []
            
        soup = BeautifulSoup(resp.text, 'html.parser')
        repos = []
        
        # éå†æ–‡ç« åˆ—è¡¨ (GitHub ç›®å‰ä½¿ç”¨ article.Box-row)
        items = soup.select('article.Box-row')
        
        for item in items[:limit]: # è¿™é‡Œç›´æ¥åšæˆªæ–­
            try:
                # 1. è·å–é¡¹ç›®åå’Œé“¾æ¥
                h2_a = item.select_one('h2 a')
                if not h2_a: continue
                
                href = h2_a['href'].strip() # /owner/repo
                full_name = href.strip('/') # owner/repo
                repo_url = f"https://github.com{href}"
                
                # 2. è·å–æè¿°
                p_desc = item.select_one('p.col-9')
                description = p_desc.text.strip() if p_desc else "æ— æè¿°"
                
                # 3. è·å– Stars (ç²—ç•¥è·å–å½“æ—¥æ–°å¢æˆ–æ€»æ˜Ÿæ•°)
                # GitHub Trending é¡µé¢ç»“æ„ç»å¸¸å˜ï¼Œè¿™é‡Œå–æœ€æ˜¾è‘—çš„æ•°å­—
                stars_elem = item.select_one('a[href$="/stargazers"]')
                stars = stars_elem.text.strip() if stars_elem else "N/A"
                
                repos.append({
                    "repo_name": full_name,
                    "url": repo_url,
                    "description": description,
                    "stars": stars
                })
            except Exception as e:
                print(f"âš ï¸ è§£æå•ä¸ªé¡¹ç›®å‡ºé”™: {e}")
                continue
                
        return repos

    except Exception as e:
        print(f"âŒ çˆ¬è™«å¼‚å¸¸: {e}")
        return []

# === 4. AI æ‘˜è¦ç”Ÿæˆ ===
def generate_ai_summary(client, repo, model_name):
    if not client: return ""
    
    name = repo['repo_name']
    desc = repo['description']
    
    prompt = (
        f"é¡¹ç›®: {name}\n"
        f"æè¿°: {desc}\n"
        "è¯·ç”¨ä¸­æ–‡ä¸€å¥è¯æ¦‚æ‹¬è¿™ä¸ªé¡¹ç›®çš„æ ¸å¿ƒåŠŸèƒ½ï¼Œä¸è¦åºŸè¯ã€‚"
    )

    try:
        response = client.chat.completions.create(
            model=model_name,
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæŠ€æœ¯ä¸“å®¶ã€‚"},
                {"role": "user", "content": prompt}
            ],
            max_tokens=100,
            temperature=0.3
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        print(f"âš ï¸ AI æ¥å£é”™è¯¯: {e}")
        return ""

# === 5. Markdown æ„å»º ===
def build_section(title, repos, settings, history, llm_client):
    section = f"## {title}\n\n"
    section += "| æ’å | é¡¹ç›® | Stars | ç®€ä»‹ (AI/Raw) |\n"
    section += "| :--- | :--- | :--- | :--- |\n"

    for idx, repo in enumerate(repos, 1):
        name = repo['repo_name']
        url = repo['url']
        stars = repo['stars']
        raw_desc = repo['description'].replace('|', '\|').replace('\n', ' ')
        
        final_desc = raw_desc
        
        # AI é€»è¾‘
        if settings['enable_llm']:
            if name in history:
                # å‘½ä¸­ç¼“å­˜
                final_desc = f"ğŸ¤– {history[name]['summary']}"
            elif llm_client:
                # è°ƒç”¨ AI
                ai_sum = generate_ai_summary(llm_client, repo, settings.get('ai_model', 'gpt-3.5-turbo'))
                if ai_sum:
                    final_desc = f"ğŸ¤– {ai_sum}"
                    # å†™å…¥ç¼“å­˜
                    history[name] = {
                        "summary": ai_sum,
                        "updated_at": datetime.datetime.now().strftime("%Y-%m-%d")
                    }
        
        # æˆªæ–­é•¿æ–‡æœ¬
        if len(final_desc) > 150:
            final_desc = final_desc[:147] + "..."

        section += f"| {idx} | [{name}]({url}) | {stars} | {final_desc} |\n"
    
    return section

# === 6. å½’æ¡£ç´¢å¼•åˆ—è¡¨ ===
def get_archive_list(archive_dir):
    if not os.path.exists(archive_dir): return []
    files = [f for f in os.listdir(archive_dir) if f.endswith('.md')]
    files.sort(reverse=True) # æ—¥æœŸå€’åº
    
    lines = []
    for f in files:
        date = f.replace('.md', '')
        lines.append(f"| {date} | [æŸ¥çœ‹æ—¥æŠ¥](./{archive_dir}/{f}) |")
    return lines

# === ä¸»ç¨‹åº ===
def main():
    config = load_config()
    settings = config['settings']
    history = load_history(settings['history_file'])
    
    # åˆå§‹åŒ– AI å®¢æˆ·ç«¯
    llm_client = None
    if settings['enable_llm']:
        api_key = os.environ.get("OPENAI_API_KEY")
        base_url = os.environ.get("OPENAI_BASE_URL")
        if api_key:
            llm_client = OpenAI(api_key=api_key, base_url=base_url)

    # å‡†å¤‡å†…å®¹
    today = datetime.datetime.now().strftime("%Y-%m-%d")
    update_time = datetime.datetime.now().strftime("%Y-%m-%d %H:%M UTC")
    
    report_content = settings['readme_header'].replace("{{ update_time }}", update_time) + "\n\n"

    # éå†ä»»åŠ¡
    for item in config['collections']:
        limit = settings.get('top_list_limit', 10)
        repos = scrape_github_trending(item['url'], limit=limit)
        
        if repos:
            section_md = build_section(item['title'], repos, settings, history, llm_client)
            report_content += section_md + "\n"
        
        time.sleep(2) # é˜²å° IP å»¶è¿Ÿ

    # ä¿å­˜ä»Šæ—¥å½’æ¡£
    archive_dir = settings['archive_dir']
    os.makedirs(archive_dir, exist_ok=True)
    with open(os.path.join(archive_dir, f"{today}.md"), "w", encoding="utf-8") as f:
        f.write(report_content)
    print(f"âœ… ä»Šæ—¥å½’æ¡£å·²ç”Ÿæˆ: {today}.md")

    # æ›´æ–° README (å¤´éƒ¨ + å½’æ¡£åˆ—è¡¨)
    archive_list = get_archive_list(archive_dir)
    history_section = "\n## ğŸ—‚ å†å²å½’æ¡£ (Archives)\n\n| æ—¥æœŸ | é“¾æ¥ |\n| :--- | :--- |\n"
    history_section += "\n".join(archive_list[:14]) # æ˜¾ç¤ºæœ€è¿‘14å¤©
    
    with open(settings['readme_file'], "w", encoding="utf-8") as f:
        f.write(report_content + history_section)
    print("âœ… README å·²æ›´æ–°")

    # ä¿å­˜ç¼“å­˜
    save_history(settings['history_file'], history)

if __name__ == "__main__":
    main()
